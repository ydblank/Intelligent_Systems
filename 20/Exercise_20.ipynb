{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTM5ykIemjh2"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_XLpcFO5mjh5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8z1RZLWmjh7"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s4TuRQ5Zmjh9"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "# randomness\n",
        "seed = 42\n",
        "np.random.seed = seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n_5QhD0mjh-"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sx5wvAEvmjh_"
      },
      "outputs": [],
      "source": [
        "# Data downloaded from - https://www.kaggle.com/competitions/data-science-bowl-2018/data\n",
        "#importing datasets\n",
        "\n",
        "TRAIN_PATH = 'stage1_train'\n",
        "TEST_PATH = 'stage1_test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mubyQQtpmjh_"
      },
      "source": [
        "### Reading all the images present in the subfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwllA-OomjiA"
      },
      "outputs": [],
      "source": [
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHQybO__mjiA"
      },
      "outputs": [],
      "source": [
        "train_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytiz2hr5mjiA"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFHR4O35mjiB"
      },
      "outputs": [],
      "source": [
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TfPyvcMmjiB"
      },
      "source": [
        "# Resizing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CagbrVy7mjiB"
      },
      "outputs": [],
      "source": [
        "print('Resizing training images and masks')\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH+ '/' + id_\n",
        "    print(path)\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "\n",
        "    Y_train[n] = mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_mxk8XxmjiC"
      },
      "source": [
        "Testing the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vToxevaqmjiC"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print('Resizing test images')\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + '/' + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfspLx4YmjiD"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXq8hwXrmjiD"
      },
      "source": [
        "# Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-hCfBflmjiD"
      },
      "outputs": [],
      "source": [
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
        " kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        " kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu',\n",
        "kernel_initializer='he_normal', padding='same')(c5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mm9fNLdmjiE"
      },
      "source": [
        "# Expansion Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJuJw6bqmjiE"
      },
      "outputs": [],
      "source": [
        "# Expansion Paths\n",
        "\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='linear', kernel_initializer='he_normal',\n",
        "padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='linear', kernel_initializer='he_normal',\n",
        "padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\n",
        "padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\n",
        "padding='same')(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal',\n",
        "padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal',\n",
        "padding='same')(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',\n",
        "padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',\n",
        "padding='same')(c9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN3yAwpXmjiE"
      },
      "source": [
        "# Outputs + Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFi-cjhvmjiE"
      },
      "outputs": [],
      "source": [
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDH_ynZmmjiF"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjWmJgEomjiF"
      },
      "source": [
        "# Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1DCWMjZmjiF"
      },
      "outputs": [],
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5',\n",
        "verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
        "\n",
        "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=30,\n",
        "callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATSn36-mjiF"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzepBtQMmjiF"
      },
      "outputs": [],
      "source": [
        "idx = random.randint(0, len(X_train))\n",
        "\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()\n",
        "\n",
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hw_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}